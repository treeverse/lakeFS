name: Spark metadata client
on:
  push:
    paths:
      - "clients/spark/**"
    branches:
      - master
  pull_request:
  workflow_dispatch:
jobs:
  lakefs-spark:
    name: lakeFS Spark metadata client
    runs-on: ubuntu-20.04
    steps:
      - name: Check-out code
        uses: actions/checkout@v2
      - name: Setup Scala
        uses: olafurpg/setup-scala@v10
      - name: validate format
        working-directory: clients/spark
        run: sbt scalafmtCheck
      - name: validate unused
        working-directory: clients/spark
        run: sbt "scalafix --check"
      - name: package
        working-directory: clients/spark
        run: sbt package
      - name: Prepare publish credentials
        if: github.event_name == 'workflow_dispatch' || github.event_name == 'pull_request' # TODO delete after ||
        run: |
          cat << EOF >> ~/.sbt/credentials \
          realm=Amazon S3\
          host=treeverse-clients-us-east.s3.amazonaws.com\
          user=${AWS_ACCESS_KEY_ID}\
          password=${AWS_SECRET_ACCESS_KEY}\
          EOF
          cat << EOF >> ~/.sbt/sonatype_credentials \
          realm=Sonatype Nexus Repository Manager\
          host=s01.oss.sonatype.org\
          user=${OSSRH_USERNAME}\
          password=${OSSRH_TOKEN}\
          EOF
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          OSSRH_USERNAME: ${{ secrets.OSSRH_USERNAME }}
          OSSRH_TOKEN: ${{ secrets.OSSRH_TOKEN }}
      - name: Publish artifacts
        if: github.event_name == 'workflow_dispatch' || github.event_name == 'pull_request' # TODO delete after ||
        run: make publish-scala