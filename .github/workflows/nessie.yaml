name: Nessie
on:
  pull_request:
  push:
    branches:
      - master

jobs:
  check-secrets:
    name: Check if secrets are available.
    outputs:
      secretsavailable: ${{ steps.enablejobs.outputs.secretsavailable }}
    runs-on: ubuntu-20.04
    steps:
      - id: enablejobs
        env:
          ENABLE_NEXT_JOBS: ${{ secrets.AWS_ACCESS_KEY_ID }}
        run: |
          echo "Enable next jobs based on secrets existence: ${{ env.ENABLE_NEXT_JOBS != '' }}"
          echo "::set-output name=secretsavailable::${{ env.ENABLE_NEXT_JOBS != '' }}"

  deploy-image:
    name: Build and push Docker image
    needs: check-secrets
    if: needs.check-secrets.outputs.secretsavailable == 'true'
    runs-on: ubuntu-20.04
    steps:
      - name: Checkout
        uses: actions/checkout@v2

      - name: Setup UI (node 10)
        uses: actions/setup-node@v1
        with:
          node-version: '10.x'

      - name: Setup Go
        uses: actions/setup-go@v1
        with:
          go-version: 1.15.2
        id: go

      # No way to share code between workflows :-( If you change this, find and change the
      # same code wherever "Find Go module and build caches" appears!
      - name: Find Go module and build caches
        run: |
          echo GOMODCACHE=`go env GOMODCACHE` >> $GITHUB_ENV
          echo GOCACHE=`go env GOCACHE` >> $GITHUB_ENV
          cat $GITHUB_ENV
      - name: Cache Go modules and builds
        uses: actions/cache@v2
        env:
          cache-name: cache-go-modules
        with:
          path: |
            ${{ env.GOMODCACHE }}
            ${{ env.GOCACHE }}
          key: ${{ runner.os }}-build-${{ env.cache-name }}-${{ hashFiles('go.mod', 'go.sum') }}
          restore-keys:
            ${{ runner.os }}-build-${{ env.cache-name }}-
            ${{ runner.os }}-build-
            ${{ runner.os }}-

      - name: Generate code
        run: |
          make gen

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Extract version
        shell: bash
        run: echo "::set-output name=tag::sha-$(git rev-parse --short HEAD | sed s/^v//g)"
        id: version

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      - name: Build and push to Amazon ECR
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY_LAKEFS: lakefs
        run: |
          set +e
          describe_image="$( aws ecr describe-images --repository-name $ECR_REPOSITORY_LAKEFS --image-ids imageTag=${{ steps.version.outputs.tag }})"
          if [ $? -eq 0 ]; then
            echo "Image exists"
          else
            echo "Image doesn't exist"
            docker build -t $ECR_REGISTRY/$ECR_REPOSITORY_LAKEFS:${{ steps.version.outputs.tag }} --build-arg VERSION=${{ steps.version.outputs.tag }} .
            docker push $ECR_REGISTRY/$ECR_REPOSITORY_LAKEFS:${{ steps.version.outputs.tag }}
          fi

  run-system:
    name: Run latest lakeFS app
    needs: deploy-image
    runs-on: ubuntu-20.04
    strategy:
      matrix:
        cataloger:
          - mvcc
          - rocks
    steps:
      - name: Check-out code
        uses: actions/checkout@v2
      - name: Setup Go
        uses: actions/setup-go@v2
        with:
          go-version: 1.15.2
        id: go
      - name: Extract version
        shell: bash
        run: echo "::set-output name=tag::sha-$(git rev-parse --short HEAD | sed s/^v//g)"
        id: version
      - name: Generate code
        run: |
          make gen
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1
      - name: Run lakeFS S3
        env:
          TAG: ${{ steps.version.outputs.tag }}
          # Setting Account_ID as a secret as a way to avoid specifying it here
          REPO: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.us-east-1.amazonaws.com
          LAKEFS_CATALOGER_TYPE: ${{ matrix.cataloger }}
          LAKEFS_STATS_ENABLED: "false"
          LAKEFS_BLOCKSTORE_TYPE: s3
          LAKEFS_GATEWAYS_S3_DOMAIN_NAME: s3.local.lakefs.io:8000
          DOCKER_REG: ${{ steps.login-ecr.outputs.registry }}
          AWS_ACCESS_KEY_ID: ${{ secrets.NESSIE_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.NESSIE_AWS_SECRET_ACCESS_KEY }}
        run: docker-compose -f nessie/ops/docker-compose.yaml up --quiet-pull -d
      - name: Run Nessie S3
        env:
          NESSIE_STORAGE_NAMESPACE: s3://nessie-system-testing/${{ github.run_number }}-${{ matrix.cataloger }}
          NESSIE_AWS_ACCESS_KEY_ID: ${{ secrets.NESSIE_AWS_ACCESS_KEY_ID }}
          NESSIE_AWS_SECRET_ACCESS_KEY: ${{ secrets.NESSIE_AWS_SECRET_ACCESS_KEY }}
        run: go test -v ./nessie --system-tests
      - name: Check files in S3 bucket
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.NESSIE_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.NESSIE_AWS_SECRET_ACCESS_KEY }}
        run: |
            FILES_COUNT=`aws s3 ls s3://nessie-system-testing/${{ github.run_number }}-${{ matrix.cataloger }} --recursive | wc -l`
            [ $FILES_COUNT -gt 5 ]
      - name: lakeFS Logs on s3 failure
        if: ${{ failure() }}
        continue-on-error: true
        run: docker-compose -f nessie/ops/docker-compose.yaml logs --tail=1000 lakefs
      - name: Export DB
        if: ${{ always() }}
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.NESSIE_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.NESSIE_AWS_SECRET_ACCESS_KEY }}
        run: |
            cd nessie/ops
            docker-compose ps -q postgres && docker-compose exec -T postgres pg_dumpall --username=lakefs | gzip | aws s3 cp - s3://nessie-system-testing/${{ github.run_number }}-${{ matrix.cataloger }}/dump.gz
      - name: Run lakeFS S3 to use with local API key
        env:
          TAG: ${{ steps.version.outputs.tag }}
          # Setting Account_ID as a secret as a way to avoid specifying it here
          REPO: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.us-east-1.amazonaws.com
          LAKEFS_CATALOGER_TYPE: ${{ matrix.cataloger }}
          LAKEFS_STATS_ENABLED: "false"
          LAKEFS_BLOCKSTORE_TYPE: s3
          LAKEFS_GATEWAYS_S3_DOMAIN_NAME: s3.local.lakefs.io:8000
          DOCKER_REG: ${{ steps.login-ecr.outputs.registry }}
          AWS_ACCESS_KEY_ID: ${{ secrets.NESSIE_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.NESSIE_AWS_SECRET_ACCESS_KEY }}
        run: |
          docker-compose -f nessie/ops/docker-compose.yaml down -v
          docker-compose -f nessie/ops/docker-compose.yaml up --quiet-pull -d
      - name: Run Nessie S3 with local API key
        env:
          NESSIE_STORAGE_NAMESPACE: s3://nessie-system-testing/${{ github.run_number }}-${{ matrix.cataloger }}-local-api-key
        run: go test -v ./nessie --system-tests --use-local-credentials --coverprofile=nessie-cover.out --cover
      - name: Run lakeFS GS
        env:
          TAG: ${{ steps.version.outputs.tag }}
          # Setting Account_ID as a secret as a way to avoid specifying it here
          REPO: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.us-east-1.amazonaws.com
          LAKEFS_CATALOGER_TYPE: ${{ matrix.cataloger }}
          LAKEFS_STATS_ENABLED: "false"
          LAKEFS_BLOCKSTORE_TYPE: gs
          LAKEFS_GATEWAYS_S3_DOMAIN_NAME: s3.local.lakefs.io:8000
          DOCKER_REG: ${{ steps.login-ecr.outputs.registry }}
          AWS_ACCESS_KEY_ID: ""
          AWS_SECRET_ACCESS_KEY: ""
          LAKEFS_BLOCKSTORE_GS_CREDENTIALS_JSON: ${{ secrets.LAKEFS_BLOCKSTORE_GS_CREDENTIALS_JSON }}
        run: |
            docker-compose -f nessie/ops/docker-compose.yaml down -v
            docker-compose -f nessie/ops/docker-compose.yaml up --quiet-pull -d
      - name: Run Nessie GS
        env:
          NESSIE_STORAGE_NAMESPACE: gs://nessie-system-testing/${{ github.run_number }}-${{ matrix.cataloger }}
        run: go test -v ./nessie --system-tests
      - name: lakeFS Logs on GS failure
        if: ${{ failure() }}
        continue-on-error: true
        run: docker-compose -f nessie/ops/docker-compose.yaml logs --tail=1000 lakefs
      - name: Publish coverage
        uses: codecov/codecov-action@v1
        with:
          files: ./nessie-cover.out
          fail_ci_if_error: false
