---
layout: default
title: AWS S3
description: This guide explains how to configure AWS S3 as the underlying storage layer.
parent: Prepare Your Storage
grand_parent: Set up lakeFS
nav_order: 10
has_children: false
---

# Prepare Your AWS S3 Bucket

1. From the S3 Administration console, choose `Create Bucket`.
2. Make sure that you:
   1. [Block public access](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-block-public-access.html).
   2. **Disable** [Object Lock](https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock-console.html).

There are two types of S3 bucket permission policies that can be used: the default [permission
policy](#permission-policy) and the [metadata-only](#metadata-permissions-policy-advanced) permission policy.
Pick the one that best describes your use case and to add it, go to the `Permissions` tab, and paste it.

## Permission Policy

By setting this bucket policy you'll be able to perform metadata operations as well as to upload/download objects to/from your bucket using lakeFS.
To upload or download an object to your storage namespace using lakeFS, you can use the [API](../../reference/api.md), the CLI tool
[`lakectl`](../../reference#lakectl-fs), the [Spark metadata client](../../reference/spark-client.md),
or the [S3 gateway](../../integrations/spark.md#access-lakefs-using-the-s3a-gateway).

```json
{
   "Id": "<POLICY_ID>",
   "Version": "2012-10-17",
   "Statement": [
      {
         "Sid": "lakeFSObjects",
         "Action": [
            "s3:GetObject",
            "s3:PutObject",
            "s3:AbortMultipartUpload",
            "s3:ListMultipartUploadParts"
         ],
         "Effect": "Allow",
         "Resource": ["arn:aws:s3:::<STORAGE_NAMESPACE>/*"],
         "Principal": {
            "AWS": ["arn:aws:iam::<ACCOUNT_ID>:role/<IAM_ROLE>"]
         }
      },
      {
         "Sid": "lakeFSBucket",
         "Action": [
            "s3:ListBucket",
            "s3:GetBucketLocation",
            "s3:ListBucketMultipartUploads"
         ],
         "Effect": "Allow",
         "Resource": ["arn:aws:s3:::<BUCKET>"],
         "Principal": {
            "AWS": ["arn:aws:iam::<ACCOUNT_ID>:role/<IAM_ROLE>"]
         }
      }
   ]
}
```
* Replace `<STORAGE_NAMESPACE>` with your [storage namespace](../../understand/model.md#concepts-unique-to-lakefs) which will be in the form of `<BUCKET_NAME>/<PATH>` (`PATH` can be empty).
* Replace `<ACCOUNT_ID>` and `<IAM_ROLE>` with values relevant to your environment.
* Replace `<BUCKET>` with the **bucket** that lakeFS is managing.
* Replace `<POLICY_ID>` with a string ID of your choice.
* `IAM_ROLE` should be the role assumed by your lakeFS installation.

Alternatively, if you use an AWS user's key-pair to authenticate lakeFS to AWS, change the policy's Principal to be the user:

```json
 "Principal": {
   "AWS": ["arn:aws:iam::<ACCOUNT_ID>:user/<IAM_USER>"]
 }
```

---

You're now ready to [create your first lakeFS repository](../create-repo.md).

---

## Metadata Permissions Policy (advanced)

lakeFS requires permissions to access the `_lakefs` prefix under your storage namespace, in which the metadata
objects are stored ([learn more](../../understand/versioning-internals.md#constructing-a-consistent-view-of-the-keyspace-ie-a-commit)).  
By setting this policy you'll be able to perform only metadata operations through lakeFS, meaning that you'll **not** be able
to use lakeFS to upload or download objects. Specifically you won't be able to:
* Upload objects using the lakeFS GUI
* Upload objects through Spark using the S3 gateway
* Run `lakectl fs` commands (unless using the `--direct` flag)

This permission is useful if you upload/download objects to/from your bucket using external tools.
For example, you can use the [lakeFS Hadoop FileSystem Spark integration](../../integrations/spark.md#access-lakefs-using-the-lakefs-specific-hadoop-filesystem)
to directly access your S3 bucket while performing metadata operations through lakeFS on the objects in that bucket.

```json
{
  "Id": "<POLICY_ID>",
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "lakeFSObjects",
      "Action": [
         "s3:GetObject",
         "s3:PutObject"
      ],
      "Effect": "Allow",
      "Resource": [
         "arn:aws:s3:::<STORAGE_NAMESPACE>/_lakefs/*"
      ],
      "Principal": {
        "AWS": ["arn:aws:iam::<ACCOUNT_ID>:role/<IAM_ROLE>"]
      }
    },
     {
        "Sid": "lakeFSBucket",
        "Action": [
           "s3:ListBucket",
           "s3:GetBucketLocation"
        ],
        "Effect": "Allow",
        "Resource": ["arn:aws:s3:::<BUCKET>"],
        "Principal": {
           "AWS": ["arn:aws:iam::<ACCOUNT_ID>:role/<IAM_ROLE>"]
        }
     }
  ]
}
```
